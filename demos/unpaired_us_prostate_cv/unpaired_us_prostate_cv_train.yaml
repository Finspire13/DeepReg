train:
  # define neural network structure
  model:
    method: "ddf" # the registration method, value should be ddf / dvf / conditional
    backbone: "local" # value should be local / global / unet
    local:
      num_channel_initial: 16 # number of initial channel in local net, controls the size of the network
      extract_levels: [0, 1, 2, 3]
    unet:
      num_channel_initial: 2 # number of initial channel in u-net, controls the size of the network
      depth: 2 # depth of u-net, the input is at depth = 0, and the bottom is at depth = depth
      pooling: true # for downsampling, use non-parameterized pooling if true, otherwise use conv3d
      concat_skip: false #ã€€when upsampling, concatenate skipped tensor if true, otherwise use addition

  # define the loss function for training
  loss:
    dissimilarity:
      image:
        name: "ssd"
        weight: 0.1
      label:
        weight: 1.0
        name: "multi_scale"
        multi_scale:
          loss_type: "dice"
          loss_scales: [0, 1, 2, 4, 8, 16]
        single_scale:
          loss_type: "cross-entropy"
    regularization:
      weight: 10.0 # weight of regularization loss
      energy_type: "bending" # value should be bending / gradient-l1 / gradient-l2

  # define the optimizer
  optimizer:
    name: "adam" # value should be adam / sgd / rms
    adam:
      learning_rate: 1.0e-5
    sgd:
      learning_rate: 1.0e-4
      momentum: 0.9
    rms:
      learning_rate: 1.0e-4
      momentum: 0.9

  # define the hyper-parameters for preprocessing
  preprocess:
    batch_size: 6
    shuffle_buffer_num_batch: 1 # shuffle_buffer_size = batch_size * shuffle_buffer_num_batch

  # other training hyper-parameters
  epochs: 5000 # number of training epochs
  save_period: 100 # the model will be saved every `save_period` epochs.
